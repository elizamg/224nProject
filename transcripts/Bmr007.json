{
    "meeting_id": "Bmr007",
    "transcript": "@ @ OK . @ @ Mm - hmm . Mm - hmm . Mm - hmm . Mm - hmm . Yeah Yeah Yeah , yeah . Yeah , yeah . He 's Yeah , yeah , yeah . Yeah Yes , yes ! Yeah . Yeah . Yeah , yeah , I h I have this that infor I have th that information now . The the duration of eh of each of the overlaps . M I I haven't averaged it now but , uh I I will , uh I will do the the study of the with the with the program with the uh , the different , uh the , nnn , distribution of the duration of the overlaps . mmm , Because the the uh , @ @ is @ @ . The duration is , uh the variation the variation of the duration is uh , very big on the dat but eh Yeah . Because , on your surface eh a bit of zone of overlapping with the duration eh , overlapped and another very very short . Uh , i probably it 's very difficult to to because the the overlap is , uh on is only the in the final \" S \" of the of the the fin the the end the end word of the , um previous speaker with the the next word of the the new speaker . Um , I considered that 's an overlap but it 's very short , it 's an \" X \" with a and the idea is probably , eh when eh when eh , we studied th th that zone , eh eh , we h we have eh eh confusion with eh eh noise . With eh that fricative sounds , but uh I have new information but I have to to study . Yeah . Yeah . Yeah . Yeah . Mmm . Yeah . Yeah . Yeah . Yeah , yeah , yeah . More , yeah . Yeah . Yeah . Yeah . Yeah . Voting for Yeah . Is the same . Yeah . Yeah . @ @ Yeah Yeah . Yeah . Yeah . Yeah . Is possible to get information from the rhythmic f from the ge , eh uh , files . Yeah . The chair Yeah . A video , yeah . Only with eh uh , but eh I I I think , eh when when , y I I saw the the the the speech from PDA and , eh close talker . I I think the there is a a great difference in the in the signal . Um but eh I but eh I I I mean that eh eh in the in the mixed file you can find , uh zone with , eh great different , eh level of energy . Um I I think for , eh algorithm based on energy , eh , that um h mmm , more or less , eh , like eh eh , mmm , first sound energy detector . eh nnn . When y you the detect the the the first at at the end of of the detector of , ehm princ um . What is the the name in English ? the the , mmm , the de detector of , ehm of a word in the in the s in an isolated word in in the background That , uh I mean that when when you use , eh eh any Yeah . I I think it 's probably to work well eh , because , eh you have eh , in the mixed files a great level of energy . eh and great difference between the sp speaker . And probably is not so easy when you use the the PDA , eh that Because the signal is , eh the in the e energy level . in in that , eh eh speech file is , eh more similar . between the different eh , speaker , um I I think is eh , it will i is my opinion . It will be , eh more difficult to to detect bass - tone energy . the the change . I think that , um In the PDA . Yeah . Yeah . And the the another question , that when I review the the the work of Javier . I think the , nnn , the , nnn , that the idea of using a neural network to to get a broad class of phonetic , eh from , eh uh a candidate from the the the speech signal . If you have , eh uh , I 'm considering , only because Javier , eh only consider , eh like candidate , the , nnn , eh the silence , because it is the the only model , eh eh , he used that , eh eh nnn , to detect the the possibility of a a change between the between the speaker , Um another another research thing , different groups , eh working , eh on Broadcast News prefer to , eh to consider hypothesis eh between each phoneme . Because , I I I think it 's more realistic that , uh only consider the the the the silence between the speaker . Eh there there exists eh silence between between , eh a speaker . is is , eh eh acoustic , eh event , important to to consider . I I found that the , eh silence in in many occasions in the in the speech file , but , eh when you have , eh eh , two speakers together without enough silence between between them , eh I think eh is better to use the acoustic change detector basically and I I I IX or , mmm , BIC criterion for consider all the frames in my opinion . Yeah . Yeah . Yeah , yeah , yeah , yeah . Yeah . Yeah , yeah , yeah , yeah . Uh - huh . But , eh do do you think that if you consider all the frames to apply the the , eh the BIC criterion to detect the the the different acoustic change , eh between speaker , without , uh with , uh silence or with overlapping , uh , I think like like , eh eh a general , eh eh way of process the the acoustic change . In a first step , I mean . An - and then , eh eh without considering the you you you , um you can consider the energy like a another parameter in the in the feature vector , eh . This this is the idea . And if , if you do that , eh eh , with a BIC uh criterion for example , or with another kind of , eh of distance in a first step , and then you , eh you get the , eh the hypothesis to the this change acoustic , eh to po process Because , eh eh , probably you you can find the the eh a small gap of silence between speaker with eh eh a ga mmm , small duration Less than , eh two hundred milliseconds for example and apply another another algorithm , another approach like , eh eh detector of ene , eh detector of bass - tone energy to to consider that , eh that , eh zone . of s a small silence between speaker , or another algorithm to to process , eh the the segment between marks eh founded by the the the BIC criterion and applied for for each frame . I think is , eh nnn , it will be a an an a more general approach the if we compare with use , eh a neural net or another , eh speech recognizer with a broad class or or narrow class , because , in my opinion eh it 's in my opinion , eh if you if you change the condition of the speech , I mean , if you adjust to your algorithm with a mixed speech file and to , eh to , eh adapt the neural net , eh used by Javier with a mixed file . uh With a m mixed file , with a the mix , mix . Sorry . And and then you you , eh you try to to apply that , eh , eh , eh , speech recognizer to that signal , to the PDA , eh speech file , I I think you will have problems , because the the the the condition you you will need t t I I suppose that you will need to to to retrain it . Really ? Yeah . Yeah . Yeah . Yeah . Yeah ! the candidate . Yeah . Yeah . Yeah Yeah . But , eh I I Sorry . I I have found that when when I I analyzed the the speech files from the , eh mike , eh from the eh close eh microphone , eh I found zones with a a different level of energy . including overlap zone . including . because , eh eh depend on the position of the of the microph of the each speaker to , eh , to get more o or less energy i in the mixed sign in the signal . and then , if you consider energy to to detect overlapping in in , uh , and you process the the in the the the speech file from the the the mixed signals . The mixed signals , eh . I I think it 's it 's difficult , um only to en with energy to to consider that in that zone We have eh , eh , overlapping zone Eh , if you process only the the energy of the , of each frame . Yeah . Yeah . Yeah . Yeah . Yeah . Yeah . Yeah . Yeah . Yeah . Yeah . Yeah Yeah . Yeah . Yeah . Ah , yeah . Yeah Yeah . Yeah . Transcript one seven seven one dash one seven nine zero zero zero five seven eight two zero two one three four eight three five eight six four five two O five five O six seven eight O four O three nine O two three O six four nine two zero one five four three two seven nine three four O O five O O four O three two seven one three four five three O eight two five eight one four six nine five five seven O eight nine zero nine"
}