{
    "meeting_id": "Bmr015",
    "transcript": "Yeah . Self - learning , yeah . Can w I could always say something about transcription . I 've been but but uh , well Yeah . Yeah , yeah , yeah . This does sound like we 're doing fine , yeah . That won't do . Oh ! By throw them out completely ? Mm - hmm . Well , and s and you 're talking string - wise , you 're not talking about the entire page ? I get it . Mm - hmm . Yeah , true . Mm - hmm . Mm - hmm . No , not yet . Oh Oh . Well , if there 's space , though , between them . I mean , you can With when you space them out they don't look like , uh , forty - three anymore . Hmm . Yeah . But , you know , when you , do things like that you can always as long as you have uh , you can always search from the beginning or the end of the string . You know , so \" zero zero two \" Yeah . Yeah , well , your example was really i OK . I I would think though that the transcribe the transcripts themselves wouldn't need to have such lengthy names . So , I mean , you 're dealing with a different domain there , and with start and end times and all that , and channels and stuff , so , it 's a different set . Fine . Fine . The the news is that I 've I uh s So in s um So I 've switched to Start my new sentence . I I switched to doing the channel - by - channel transcriptions to provide , uh , the uh , tighter time bins for partly for use in Thilo 's work and also it 's of relevance to other people in the project . And , um , I discovered in the process a couple of of interesting things , which , um , one of them is that , um , it seems that there are time lags involved in doing this , uh , uh , using an interface that has so much more complexity to it . And I and I wanted to maybe ask , uh , Chuck to help me with some of the questions of efficiency . Maybe I was thinking maybe the best way to do this in the long run may be to give them single channel parts and then piece them together later . And I I have a script , I can piece them together . I mean , so it 's like , I I know that I can take them apart and put them together and I 'll end up with the representation which is where the real power of that interface is . And it may be that it 's faster to transcribe a channel at a time with only one , uh , sound file and one , uh , set of of , uh , utterances to check through . Oh , yes . OK . But , um , with the mixed , when you have an overlap , you only have a a choice of one start and end time for that entire overlap , which means that you 're not tightly , uh , tuning the individual parts th of that overlap by different speakers . So someone may have only said two words in that entire big chunk of overlap . And for purposes of of , uh , things like well , so things like training the speech - nonspeech segmentation thing . Th - it 's necessary to have it more tightly tuned than that . And w and w and , you know , is a It would be wonderful if , uh , it 's possible then to use that algorithm to more tightly tie in all the channels after that but , um , you know , I 've th the So , I I don't know exactly where that 's going at this point . But m I was experimenting with doing this by hand and I really do think that it 's wise that we 've had them start the way we have with , uh , m y working off the mixed signal , um , having the interface that doesn't require them to do the ti uh , the time bins for every single channel at a t uh , through the entire interaction . Um , I did discover a couple other things by doing this though , and one of them is that , um , um , once in a while a backchannel will be overlooked by the transcriber . As you might expect , because when it 's a b backchannel could well happen in a very densely populated overlap . And if we 're gonna study types of overlaps , which is what I wanna do , an analysis of that , then that really does require listening to every single channel all the way through the entire length for all the different speakers . Now , for only four speakers , that 's not gonna be too much time , but if it 's nine speakers , then that i that is more time . So it 's li you know , kind of wondering And I think again it 's like this it 's really valuable that Thilo 's working on the speech - nonspeech segmentation because maybe , um , we can close in on that wi without having to actually go to the time that it would take to listen to every single channel from start to finish through every single meeting . OK . Well so then then , maybe the answer is to , uh , listen especially densely in places of overlap , just so that they 're they 're not being overlooked because of that , and count on accuracy during the sparser phases . Cuz there are large s spaces of the That 's a good point . There are large spaces where there 's no overlap at all . Someone 's giving a presentation , or whatever . That 's that 's a good that 's a good thought . And , um , let 's see , there was one other thing I was gonna say . I I think it 's really interesting data to work with , I have to say , it 's very enjoyable . I really , not not a problem spending time with these data . Really interesting . And not just because I 'm in there . No , it 's real interesting . Huh . Di - digital camera . I I did i it did occur to me that this is uh , the return to the transcription , that there 's one third thing I wanted to to ex raise as a to as an issue which is , um , how to handle breaths . So , I wanted to raise the question of whether people in speech recognition want to know where the breaths are . And the reason I ask the question is , um , aside from the fact that they 're obviously very time - consuming to encode , uh , the fact that there was some I had the indication from Dan Ellis in the email that I sent to you , and you know about , that in principle we might be able to , um , handle breaths by accessi by using cross - talk from the other things , be able that in principle , maybe we could get rid of them , so maybe And I was I I don't know , I mean we had this an and I didn't couldn't get back to you , but the question of whether it 'd be possible to eliminate them from the audio signal , which would be the ideal situation , cuz Well , except that these are really truly I mean , ther there 's a segment in o the one I did n the first one that I did for i for this , where truly w we 're hearing you breathing like as if we 're you 're in our ear , you know , and it 's like it 's like I y i I mean , breath is natural , but not Except that we 're we 're trying to mimic Oh , I see what you 're saying . You 're saying that the PDA application would have uh , have to cope with breath . But OK , then the then I have two questions . Yeah ? OK , so maybe the question is notating it . Yeah ? OK , well Well this is in very interesting because i it basically has a i it shows very clearly the contrast between , uh , speech recognition research and discourse research because in in discourse and linguistic research , what counts is what 's communit communicative . And breath , you know , everyone breathes , they breathe all the time . And once in a while breath is communicative , but r very rarely . OK , so now , I had a discussion with Chuck about the data structure and the idea is that the transcripts will that get stored as a master there 'll be a master transcript which has in it everything that 's needed for both of these uses . And the one that 's used for speech recognition will be processed via scripts . You know , like , Don 's been writing scripts and and , uh , to process it for the speech recognition side . Discourse side will have this this side over he the we we 'll have a s ch Sorry , not being very fluent here . But , um , this the discourse side will have a script which will stri strip away the things which are non - communicative . OK . So then the then let 's let 's think about the practicalities of how we get to that master copy with reference to breaths . So what I would r r what I would wonder is would it be possible to encode those automatically ? Could we get a breath detector ? Well , I mean , you just have no idea . I mean , if you 're getting a breath several times every minute , and just simply the keystrokes it takes to negotiate , to put the boundaries in , to to type it in , i it 's just a huge amount of time . And you wanna be sure it 's used , and you wanna be sure it 's done as efficiently as possible , and if it can be done automatically , that would be ideal . Well , but Well , OK . So now there 's there 's another another possibility which is , um , the time boundaries could mark off words from nonwords . And that would be extremely time - effective , if that 's sufficient . OK . But that would maybe include a pause as well , and that wouldn't be a problem to have it , uh , pause plus breath plus laugh plus sneeze ? That 's what they 've been doing . So , within an overlap segment , they they do this . Yeah , you 're saying it 's uncharted territory . Mm - hmm . Yeah . OK , fair enough . I guess , um , I uh , what I was wondering is what what at what level does the breathing aspect enter into the problem ? Because if it were likely that a PDA would be able to be built which would get rid of the breathing , so it wouldn't even have to be processed at thi at this computational le well , let me see , it 'd have to be computationally processed to get rid of it , but if there were , uh , like likely on the frontier , a good breath extractor then , um , and then you 'd have to Yeah , well , see and that 's what I wouldn't know . OK . I guess there 's another aspect which is that as we 've improved our microphone technique , we have a lot less breath in the in the more recent , uh , recordings , so it 's in a way it 's an artifact that there 's so much on the on the earlier ones . OK , and it 's also the fact that they differ a lot from one channel to the other because of the way the microphone 's adjusted . OK . Transcript L , six two one . Zero two three , one nine five , eight five four . One five zero one , one , eight eight three . Nine six , six three , two five , seven eight , seven nine , two O six , four three , four six six zero . Three six , two three , six eight , three five , two four . One seven , two six , one nine , seven two , six five . Eight nine , eight seven , three two , two one , three eight . Two three three seven , seven , one nine five . Four eight eight seven , six one three five , three three five seven . Nine five eight , five one five , four two two ."
}