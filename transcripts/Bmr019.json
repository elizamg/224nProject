{
    "meeting_id": "Bmr019",
    "transcript": "C we Yeah . Mm - hmm . We should do that second , because Liz might join us in time for that . Talk about aligning people 's schedules . Yeah . If we 're very Yeah . It 's pretty sad . Yeah . No , actually I I have to I have to shuttle kids from various places to various other places . So . And I don't have and I don't , um , have a cell phone so I can't be having a conference call while driving . Plus , it would make for interesting noise background noise . Uh Oh , yeah . Oh , yeah . I 'll let I 'd let I let , uh , my five - year - old have a try at the digits , eh . Exactly . D do the lapel mikes have any directionality to them ? Because I I suppose you could make some that have sort of that you have to orient towards your mouth , and then it would Mm - hmm . It is against my head . And we know Di - did I send you some results without adaptation ? Yeah , I think I did , actually . So there was a significant loss from not doing the adaptation . Um . A a a couple percent or some I mean Well , I don't know it Overall Uh , I I don't remember , but there was there was a significant , um , loss or win from adaptation with with adaptation . And , um , that was the phone - loop adaptation . And then there was a very small like point one percent on the natives uh , win from doing , um , you know , adaptation to the recognition hypotheses . And I tried both means adaptation and means and variances , and the variances added another or subtracted another point one percent . So , it 's , um that 's the number there . Point six , I believe , is what you get with both , uh , means and variance adaptation . This exact same recognizer ? No . But but , I have I mean , people people at SRI are actually working on digits . I could and they are using a system that 's , um you know , h is actually trained on digits , um , but h h otherwise uses the same , you know , decoder , the same , uh , training methods , and so forth , and I could ask them what they get on TI - digits . Mm - hmm . Well , Adam knows how to run it , so you just make a f Mm - hmm . Mm - hmm . Mmm . Hmm . Mm - hmm . Mm - hmm . Mm - hmm . Well . But remember , we 're using a telephone bandwidth front - end here , uh , on this , uh on this SRI system , so , um , I was I thought that maybe that 's actually a good thing because it it gets rid of some of the uh , the noises , um , you know , in the the below and above the um , the , you know , speech bandwidth and , um , I suspect that to get sort of the last bit out of these higher - quality recordings you would have to in fact , uh , use models that , uh , were trained on wider - band data . And of course we can't do that or Mm - hmm . Right . But but , I would Yeah . It 's it 's easy enough to try , just run it on Now , eh , does one one issue one issue with with that is that um , the system has this , uh , notion of a speaker to which is used in adaptation , variance norm uh , you know , both in , uh , mean and variance normalization and also in the VTL estimation . So Do y ? Is ? So does so th so does does , um , the TI - digits database have speakers that are known ? And is there is there enough data or a comparable comparable amount of data to to what we have in our recordings here ? OK . Right . Uh , but I 'm not so much worried about the adaptation , actually , than than the , um , um the , uh , VTL estimation . If you have only one utterance per speaker you might actually screw up on estimating the the warping , uh , factor . So , um Right . But it 's not the amount of speakers , it 's the num it 's the amount of data per speaker . Right . Right . So OK . The key So th the system actually extracts the speaker ID from the waveform names . And there 's a there 's a script and that is actually all in one script . So there 's this one script that parses waveform names and extracts things like the , um , speaker , uh , ID or something that can stand in as a speaker ID . So , we might have to modify that script to recognize the , um , speakers , um , in the in the , uh , um , TI - digits database . Or you can fake you can fake names for these waveforms that resemble the names that we use here for the for the meetings . That would be the , sort of probably the safest way to do Uh - huh . Right . By the way , I think we can improve these numbers if we care to compr improve them by , um , not starting with the Switchboard models but by taking the Switchboard models and doing supervised adaptation on a small amount of digit data collected in this setting . Because that would adapt your models to the room acoustics and f for the far - field microphones , you know , to the noise . And that should really improve things , um , further . And then you use those adapted models , which are not speaker adapted but sort of acous you know , channel adapted use that as the starting models for your speaker adaptation . Well , I don't know . Right . Um , but , you know , I uh , my impression was that you were actually interested in the far - field microphone , uh , problem , I mean . So , you want to you want to That 's the obvious thing to try . Right ? Then , eh because you you don't have any That 's where the most m acoustic mismatch is between the currently used models and the the r the set up here . So . Mm - hmm . It is ? Uh . I I I I already adjusted this a number of times . I I can't quite seem to Yeah , I think this contraption around your head is not working so well . Right . Mm - hmm . Mm - hmm . Yeah , basically your ears are too big . I mean , mine are too . E th everybody 's ears are too big for these things . Uh What k u By the way , wh what factor of two did you ? I mean Oh , th OK . That factor of two . Mm - hmm . Mm - hmm . Mm - hmm . You want to probably choose the PZM channel that is closest to the speaker . Oh , OK . Mm - hmm . So so , but where is this now ? I mean , what 's where do we go from here ? I mean , we so we have a we have a a system that works pretty well but it 's not , you know , the system that people here are used to using to working with . So what what do we do now ? Mm - hmm . OK . OK . OK . Alright . Mm - hmm . OK . So so the key thing that 's missing here is basically the ability to feed , you know , other features i into the recognizer and also then to train the system . OK . And , uh , es I don't know when Chuck will be back but that 's exactly what he he 's gonna Oh , OK . So , I think that 's one of the things that he said he would be working on . Um . Just sort of t to make sure that we can do that and Um . It 's uh , I mean , the the front - end is f i tha that 's in the SRI recognizer is very nice in that it does a lot of things on the fly but it unfortunately is not designed and , um like the , uh , ICSI system is , where you can feed it from a pipeline of of the command . So , the what that means probably for the foreseeable future is that you have to , uh , dump out , um you know , if you want to use some new features , you have to dump them into individual files and give those files to the recognizer . OK . Oh , OK . Alright . Yeah , the the the cumbersome thing is is , um is that you actually have to dump out little little files . So for each segment that you want to recognize you have to dump out a separate file . Just like i th like th as if there were these waveform segments , but instead you have sort of feature file segments . But , you know So . So that 's actually interesting . The pruning was the same value that we used for recognition . And we had lowered that we had used tighter pruning after Liz ran some experiments showing that , you know , it runs slower and there 's no real difference in Right . So for free recognition , this the lower pruning value is better . You Correct . Right . Um , but it turned out for for to get accurate alignments it was really important to open up the pruning significantly . Um because otherwise it would sort of do greedy alignment , um , in regions where there was no real speech yet from the foreground speaker . Um , so that was one big factor that helped improve things and then the other thing was that , you know , as Liz said the we f enforce the fact that , uh , the foreground speech has to be continuous . It cannot be you cannot have a background speech hypothesis in the middle of the foreground speech . You can only have background speech at the beginning and the end . Oh Well , the I I think you can do better by uh , cloning so we have a reject phone . And you and what we wanted to try with you know , once we have this paper written and have a little more time , uh , t cloning that reject model and then one copy of it would be adapted to the foreground speaker to capture the rejects in the foreground , like fragments and stuff , and the other copy would be adapted to the background speaker . And Mm - hmm . Right . We we didn't No . We w OK . We it 's straightforward to actually just have a a penalty that doesn't completely disallows it but discourages it . But , um , we just didn't have time to play with , you know , tuning yet another yet another parameter . And really the reason we can't do it is just that we don't have a we don't have ground truth for these . So , we would need a hand - marked , um , word - level alignments or at least sort of the boundaries of the speech betw you know , between the speakers . Um , and then use that as a reference and tune the parameters of the of the model , uh , to op to get the best performance . Mm - hmm . Mm - hmm . No . Mm - hmm . We don't care what what tool you use . U uh Yeah , whatever you use . I mean , we convert it to this format that the , um , NIST scoring tool unders uh , CTM . Conversation Time - Marked file . And and then that 's the that 's what the Right . Mm - hmm . Actually , not randomly . We knew we knew that it had these insertion errors from Yeah . Yeah . Well , I think No . I think it 's actually I think what 's going on is backchannelling is something that happens in two - party conversations . And if you ask someone a question , you essentially initiating a little two - party conversation . So then you 're so and then you 're expected to backchannel because the person is addressing you directly and not everybody . Yeah . Yeah . Right . Right . And CallHome. It 's the it 's the spurt format . Oh . So maybe we should talk Uh . So s W uh , w We - So what we 're doing uh , this this is just maybe someone has s some some ideas about how to do it better , but we So we 're taking these , uh , alignments from the individual channels . We 're from each alignment we 're producing , uh , one of these CTM files , which essentially has it 's just a linear sequence of words with the begin times for every word and the duration . And and and of course Right . But it has one the first column has the meeting name , so it could actually contain several meetings . Um . And the second column is the channel . Third column is the , um , start times of the words and the fourth column is the duration of the words . And then we 're , um OK . Then we have a messy alignment process where we actually insert into the sequence of words the , uh , tags for , like , where where sentence ends of sentence , question marks , um , various other things . Uh . Right . Mm - hmm . Right . So so those are actually sort of retro - fitted into the time alignment . And then we merge all the alignments from the various channels and we sort them by time . And then there 's a then there 's a process where you now determine the spurts . That is Actually , no , you do that before you merge the various channels . So you you id identify by some criterion , which is pause length you identify the beginnings and ends of these spurts , and you put another set of tags in there to keep those straight . And then you merge everything in terms of , you know , linearizing the sequence based on the time marks . And then you extract the individual channels again , but this time you know where the other people start and end talking you know , where their spurts start and end . And so you extract the individual channels , uh , one sp spurt by spurt as it were . Um , and inside the words or between the words you now have begin and end tags for overlaps . So , you you basically have everything sort of lined up and in a form where you can look at the individual speakers and how their speech relates to the other speakers ' speech . And Yeah . So And and we In Right . Well , this is this is just Well , there 's lots of little things . It 's like there 're twelve different scripts which you run and then at the end you have what you want . But , um , at the very last stage we throw away the actual time information . All we care about is whether that there 's a certain word was overlapped by someone else 's word . So you sort of at that point , you discretize things into just having overlap or no overlap . Because we figure that 's about the level of analysis that we want to do for this paper . But if you wanted to do a more fine - grained analysis and say , you know , how far into the word is the overlap , you could do that . It 's just it 'll just require more you know , slightly different Right . Yeah . Plus , mayb I don't know , m I mean , u u Jane likes to look at data . Maybe , you know , you could you could look at this format and see if you find anything interesting . I don't know . Yeah . Mm - hmm . Well th th the other thing that that that yo that you usually don't tell your graduate students is that these deadlines are actually not that , um , you know , strictly enforced , because the because bec b Nah i Because these the conference organizers actually have an interest in getting lots of submissions . I mean , a a monetary interest . So Um . And good submission Right . Well That 's another issue , but Mm - hmm . When Mmm . Mmm . Well , then you can just Maybe you can submit the digits paper on e for the Aurora session . Yeah . But but the people I mean , a a paper that is not on Aurora would probably be more interesting at that point because everybody 's so sick and tired of the Aurora task . Well , no . If you if you have it 's to if you discuss some relation to the Aurora task , like if you use the same Um . Well , a relation other than negation , maybe , um . So . I don't know . How well does an Aurora system do on on you know , on digits collected in a in this environment ? Yeah . Maybe . Mm - hmm . Well , that 's maybe why they don't f know that they have a crummy system . I mean , a crummy back - end . No , I mean I mean , seriously , if you if you have a very No , I 'm sorry . No . I didn't mean anybody any particular system . I meant this H T K back - end . If they I don't h I don't have any stock in HTK or Entropic or anything . Right . But so , if you But maybe you should , you know , consider more using more data , or I mean If yo if you sort of hermetically stay within one task and don't look left and right , then you 're gonna Right . Mm - hmm . Mm - hmm . Mm - hmm . Mm - hmm . Hmm . Mm - hmm . Mmm . Right . OK . Whew ! Actually this this , um So , there 's another paper . It 's a Eurospeech paper but not related to meetings . But it 's on digits . So , um , uh , a colleague at SRI developed a improved version of MMIE training . And he tested it mostly on digits because it 's sort of a you know , it doesn't take weeks to train it . Um . And got some very impressive results , um , with , you know , discriminative , uh , Gaussian training . Um , you know , like , um , error rates go from I don't know , in very noisy environment , like from , uh , uh I for now I OK , now I have the order of magnit I 'm not sure about the order of magnitude . Was it like from ten percent to eight percent or from e e you know , point you know , from one percent to point eight percent ? I mean , it 's a It got better . That 's the important thing . Yeah . But it 's Yeah . Right . It 's , uh , something in Right . Yeah . Are we recording it ? OK . But you know th Mm - hmm . Can use the Oprah mike . Mm - hmm . Because it would be a different kind of meeting , that 's what I 'm But Maybe just maybe not the whole day but just , you know , maybe some I mean , part of it ? Please . Maybe the sections that are not right afte you know , after lunch when everybody 's still munching and Right . Um . Not the Yeah . Uh . The th the Wait . The The , um th the other good thing about the alignments is that , um , it 's not always the machine 's fault if it doesn't work . So , you can actually find , um , problem uh , proble You can find You can find , uh , problems with with the transcripts , um , you know , and go back and fix them . But Oh ! Mm - hmm . Mm - hmm . Mm - hmm . Mmm . Mmm . Mmm . Have a good trip . Keep in touch . No , we prefer to keep it for ourselves . Yeah , yeah . Yeah . Mmm ! Mm - hmm . Mmm . Oh . Oh , yeah . Th - it doesn't it won't leave this room . Mmm . Mmm . Mmm . Chocolate adaptation . Mmm . Mmm . Mmm . Mmm . Right . You mean that the the grouping is supposed to be synchronized ? No ? No ? It 's like a like a Greek like a Greek choir ? You know ? Like Yeah . Transcript L forty five . Forty nine , seventy seven , one six , zero three , five zero . I 'm starting over . Four nine , seven seven , one six , zero three , five zero , five O three , three two five , five two zero nine , two seven , two four , two nine , six three , five six , eight two nine zero , six four three one , six eight five five , four six nine , one five six , four seven eight one , five four eight seven , three , five five five , one six three one , two , eight three eight , eight zero nine , zero seven four , one six four seven . No ."
}