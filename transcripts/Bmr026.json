{
    "meeting_id": "Bmr026",
    "transcript": "That 's our system . Mmm . Speaking Hmm . So does she have transcribers right now who are basically sitting idle because there 's no data back from IBM no ? Oh . Oh , OK . Because I I need to ask Jane whether it 's it would be OK for her um , s some of her people to transcribe uh some of the initial data we got from the SmartKom data collection , which is these short like five or seven minute sessions . Um and we want it You know , we need The Again , we we have a similar uh logistic set - up where we are supposed to send the data to Munich and get it transcribed and get it back . But to get going we would like some of the data transcribed right away so we can get started . And so um I wanted to ask Jane if if uh , you know , maybe one of their transcribers could could do I mean since these are very short , that should really be uh , um It 's Yeah . It 's only two Right , s Yeah . So So it 's basically one channel to transcribe . And it 's One session is only uh like seven Right . And some of it is read speech , so we could give them the the thing that they 're reading and they just may And so um , um , I guess since she 's I was gonna ask her but since she 's not around I maybe I 'll Uh if if that 's OK with you to to , you know , get that stuff uh to ask her for that , then I 'll do that . Yeah . OK , yeah . Alrighty . Mm - hmm . Really ? So is that Because there 's some people um It would be cool if we could uh get that to work uh at at SRI because the um we have m m We have more Windows machines to run the Right . Mmm . I I wonder if if we should contribute our changes back to the authors so that they maintain those changes along We have ? Oh . Oh , OK . So So Well But But it would be cool if the Transcriber interface had like another window for the you know , maybe above the waveform where it would show some arbitrary valued function that is that is you know time synchron ti ti time synchronous with the wavform . Right . Right . But it would almost be like having another waveform displayed . S Right . Mm - hmm . Mmm . Yeah . But you still need to store the disks somehow . So Oh you mean you put them inside the pizza boxes for the Oh . Mmm . Plus we 're talking about buying a second dis uh , file server . I see Oh , I see . You mean he won't set up the mmm . XG ? That 's also where we store the The uh Hub - five training set waveforms , right ? Right . But I 've also been storing I 've been storing the feature files there and I guess I can s start deleting some because we now know what the best features are and we won't be using the old ones anymore . Uh Oh thats XA Oh that 's X Maybe I 'm confu Oh no I 'm sorry . Oh OK . I think you 're right . It 's XH and D The b I 'm also using DG I got that confused . OK . OK . Th - The One Mmm . One One On - One thing to in to um t to do when you need to conserve space is I bet there are still some old , uh , like , nine gig disks , uh , around and you can probably consolidate them onto larger disks and and you know recover the space . Right . Mm - hmm . Mmm . Mmm . Maybe we can put some disks in the in that back room there . To the machine that collects the data . So then you could , at least temporarily , store stuff there . The only What do you mean it 's not on the net ? Oh because it 's because it 's an ACIRI machine ? Oh , oh oh . But that can't be that hard . I mean Oh , hhh . Mm - hmm . Is this gotta be in the morning ? Or Because you know I Fridays I have to leave uh like around uh two . So if it could be before that would be be Oh , OK , alright . Oh I 'm sorry , I misunderstood . I thought you are OK . Alright . Mm - hmm . OK . Mmm . Um Uh One thing I mean we in past meetings we had um also a you know various variously talked about the um work that w uh was happening sort of on the on the recognition side um but isn't necessarily related to meetings uh specifically . So . Um . And I wondered whether we should maybe have um a separate meeting and between you know , whoever 's interested in that because I feel that uh there 's plenty of stuff to talk about but it would be sort of um maybe the wrong place to do it in this meeting if uh Well , it 's that It 's just gonna be ver very boring for people who are not you know , sort of really interested in the details of the recognition system . w Well I know Well , Jane an Well you mean in a separate meeting or ha ha talking about it in this OK . So , uh , uh , Liz and Jane probably . Uh . Uh , if you wanna put it that way . Right . I mean it it 's sort of I mean when when the talk is about data collection stuff , sometimes I 've you know , I I 'm bored . So it 's I c I can sympathize with them not wanting to i to to be uh you know If I cou you know this could I 'm not sure I wanna Yeah and Mm - hmm . And we don't have to do it every week . We could do it every other week or so . You know , whatev or whenever we feel like we We could do that , yeah . I I Personally I 'd I 'm not in favor of more meetings . Um . Because , uh . You know . Right . We feel We feel obligated to collect more data . ummh . ummh . OK . Mm - hmm . Mm - hmm . Mm - hmm . Mm - hmm . Right . So um . So so we could talk a little bit about that now if if there 's some time . Um I jus So the latest result was that um um yot I tested the uh the sort of final version of the PLP configuration um on development test data for for this year 's Hub - five test set . And the recognition performance was exactly , and I mean exactly up to the you know , the first decimal , same as with the uh Mel Cepstra front - end . Yes . Uh , well i there was a little bit of a i overall . They They were The males I think were slightly better and the females were slightly worse but nothing really . I mean definitely not significant . And then the really nice thing was that if if we combine the two systems we get a one and a half percent improvement . So . t With N - best ROVER , which is like our new and improved version of ROVER . Which u actually uses the whole N - best list from both systems to mmm , uh c combine that . Yeah . And , the And And so uh after I told the my uh colleagues at SRI about that , you know , now they definitely want to , you know , uh , have a Next time we have an evaluation they want to do uh , you know , basically a at least the system combination . Um , and , you know , why not ? Uh . So . Uh w what do you mean ? More features in the sense of front - end features or in the sense of just bells and whistles ? Oh I mean Yeah . Well Right . So , we cou Yeah . That 's the the the There 's one thing uh I mean you don't want to overdo it because y every front - end You know , if you you know you basically multiply your effort by N , where N is a number of different systems and Um . So . So one one compromise would be to only to have the everything up to the point where you generate lattices be basically one system and then after that you rescore your lattices with the multiple systems and combine the results and that 's a fairly painless um thing . So . I I think so . Yeah . Maybe a little less because at that point the error rates are lower and so if You know , maybe it 's only one percent or something but that would still be worthwhile doing . So . Um Jus - You know , just wanted to let you know that that 's working out very nicely . And then we had some results on digits , uh , with um We We So this was uh really really sort of just to get Dave going with his um experiments . And so , uh . But as a result , um , you know , we were sort of wondering why is the Hub - five system doing so well on the digits . And the reason is basically there 's a whole bunch of read speech data in the Hub - five training set . And you c And Not all of No it 's actually , digits is only a maybe a fifth of it . The rest is is read is read TIMIT data and uh ATIS data and Wall Street Journal and stuff like that . A fifth would be maybe uh two hours something . Right . But it definitely helps to have the other read data in there because we 're doing You know the error rate is half of what you do if you train only on ti uh TIMIT uh not TIMIT uh TI - digits , which is only what two hours something ? So . Uh , more read speech data definitely helps . And you can leave out all the conversational data with no performance penalty . That 's e That was e Right , right . Right . Oh , yeah . So we only for the Hub - five training , we 're only using uh a fairly small subset of the Macrophone database . Um , so , you could beef that up and probably do even better . Yeah . Yeah . Right . Well , I mean that 's plenty of read speech data . I mean , Wall Street Journal , uh , take one example . But um . So , you know that might be useful for the people who train the the digit recognizers to to use uh something other than TI - digits . OK . Mm - hmm . Mmm . Mm - hmm . Mm - hmm . Mm - hmm . Right . Well , that was that . And then I th guess Chuck and I had some discussions about how to proceed with the tandem uh system and You wanna You wanna see where that stands ? @ @ An - And one side effect of that would be that it 's um that the phone set would change . So the MLP would be trained on I think only forty - six or forty - eight forty - eight phones ? Uh which is smaller than the um than the phone set that that we 've been using so far . And that that that will probably help , actually , because um the fewer dimensions uh e the less trouble probably with the as far as just the um , um Just You know we want to try things like deltas on the tandem features . And so you h have to multiply everything by two or three . And so , you know , fewer dimensions in the phone set would be actually helpful just from a logistics point of view . Right . Exactly . So so that was the other thing . And then we wanted to s just limit it to maybe uh something on the same order of dimensions as we use in a standard um front - end . So that would mean just doing the top I don't know ten or twelve or something of the KLT dimensions . Right . But then And then something Once we have the new M L P trained up , uh one thing I wanted to try just for the fun of it was to actually run uh like a standard hybrid system that is based on you know , those features uh and uh retrain MLP and also the you know , the dictionary that we use for the Hub - five system . Exactly . Yeah . So that would basically give us a , um , more hopefully a a better system um because you know , compared to what Eric did a while ago , where he trained up , I think , a system based on Broadcast News and then uh tra retraining it on Switchboard or s uh and But he I think he d he didn't he probably didn't use all the training data that was available . And his dictionary probably wasn't as tuned to um conversational speech as as the as ours is . So . And the dictionary made a huge difference . Uh . We we made some improvements to the dictionary 's uh to the dictionary about two years ago which resulted in a uh something like a four percent absolute error rate reduction on Switchboard , which Mm - hmm . Mmm . Mm - hmm . Mm - hmm . Yeah . Mm - hmm . Yeah . OK . Yeah . Right . Yeah . Mmm . But that w Even that that number Right . And And that number I think was on Switchboard - one data , right ? Where the error rate now is in the twenties . So , um . That 's yet s Right . So it would be So it would be good t to sort of r re uh just at least to give us an idea of how well the hybrid system would do . Mm - hmm . Right . And the other thing that that would help us to evaluate is to see how well the M L P is trained up . Right ? Because it 's a pretty good um indicator of that . So it 's sort of a sanity check of the M L P outputs before we go ahead and train up the uh you know , use them as a basis for the tandem system . No . Sure . Not But Oh oh that 's a good question . Yeah , we we weren't sure whether it 's worth to just use the alignments um from the S R I recognizer or whether to actually go through one or more iterations of embedded training where you realign . Mm - hmm . Mm - hmm . Right . OK . Alright . But But so I Well but i But in your experience I mean uh have you seen big improvements in s on some tasks with embedded training ? Or was it sort of small - ish uh improvements that you got Right . That are from another Right . Right . So you you started training with outputs from a with alignments that were generated by the Cambridge uh system ? And then Uh . Hmm . Well , that might probably just Hmm . That was probably because your initial system I mean your system was ba worse than Cambridge 's . And you Um . It wasn't ? Really ? That 's weird . That 's That 's weird . No I mean it 's weird that it did I 'm sorry . It 's w It 's weird that it got worse . Oh actually it 's not that weird because we have seen We have seen cases where acoustic retraining the acoustic models after some other change made matters worse rather than better . Yeah . Mm - hmm . You mean with soft targets ? Or ? Sorry , I 'm sor I missed What What 's the key issue here ? Yeah . Mm - hmm . OK . Uh , I think that has about Well i you 'd would be gender - dependent training , right ? So So I think it 's uh that 's about mmm , something like thirty hours . Thirty hours per gender . I I think so . I 'll It 's definitely less than a hundred You know , it 's more like like thirty forty hours something like that . Yeah . Mm - hmm . Remember you 'll have a smaller output layer so there 's gonna be fewer parameters there . And then OK . Yeah . Oh I see , I see , yeah , of course . Yeah . It 's negligible , OK . Uh - huh . Was that gender - dependent or independent ? Mm - hmm . Mm - hmm . OK . Right . I actually have to go . So . Yeah . I figured . Read your digits ."
}