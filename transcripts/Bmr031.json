{
    "meeting_id": "Bmr031",
    "transcript": "There 're some words that weren't See , there 're some stretches that weren't even in one or the other , so What are you gonna do about those , though ? You 're never Sure . Mm - hmm . Mm - hmm . You mean , pi will be close to one half ? That 's new . Right . You know , this this raises some Mm - hmm . How do you transcribe that ? Oh . B uh We can Well , we already use it for digit training . I mean Well , we did do some training on digits uh , rather adaptation on digits digits . I mean , supervised adaptation . So . Yeah . I mean , uh Well , I would I would love to do some , um you know , with adaptation you can use fairly small amount of data to improve your performance . Um , and n you know , it 's just basically , uh uh You know , I I don't have to time to to do too much these days except what I 'm already doing . So um , but if there 's some someone has some free time , I 'm I 'll be happy to show them how it works and you can play with it . No , supervised adaptation . So , we 're doing s unsupervised speaker adaptation . But you could build a test set which you sort of take your models and ada do supervised adaptation . And then you start with the speaker adaptation from sort of channel - adapted or room - adapted or whatever . Right . It 's it 's sort of like in , um , Broadcast News because you have those people who re - occur over and over . I mean , the anchor speakers tend typically . So , um m m m m Yeah . As long as you 're aware that you 're doing that , that 's I don't see that as a problem . Mm - hmm . Yeah . Hmm . But it would be interesting to hear what they intend to do about the speaker overlap , for instance . It could be interesting . Well , it will be interesting to find out why they are choosing a higher sampling But then they 're just they 're just there 's just deferring the problem to later and they might save themselves a lot of disk space problems by doing it right away . I mean that 's wha That 's like three times three times as much disk space . We should warn them that these disk space issues are gonna creep up on them very fast . Right . Mmm Huh . Linguistic Data Consortium . We should just talk less . Uh , OK . So f so for dis for distribution purposes it might make sense to split it by channel , uh , rather than by meetings . So , you could distribute , like , only the near - field signals , uh , uh , uh , together for a bunch of meetings and then have a second row . Yeah . Mmm . Right . But the University of Hawaii has issued a request . Yeah . Uh , you know those Europeans . They got a lot of vaca Mm - hmm . Mm - hmm . So , we had the the transcribers have trouble with your backchannel , because Yeah , with your backchannels . Because sometimes you have this sort of this this \" uh - huh \" that you don't n So there 's \" uh - huh \" and then there 's \" aha ! \" . And it 's not quite clear always what what it is you mean . Yeah . Yeah . Mm - hmm . Mm - hmm . u Do you take do you take feature requests ? That would th w s Well , actually , I think it is worth doing because here 's the thing . We 're sort of we 're starting to move from transcription to annotation . And the Transcriber interface is fine if essentially what you 're doing is stringing words together to p to make transcripts . But , um , in for instance , what we 're doing now w with , uh , Communicator data , but which we would like to do with Meeting data , is to actually label utterances , or words , or whatever units you want with , uh , you know , basically doing a multiple choice type of labelling . And for those type of tasks , it wou it 's much more efficient to present , uh , the th p present a bunch of , uh , clickable buttons or whatever and , um Hmm . And and th that 's actually a good model , which is what this current tool that we 're using has , is to atta to associate these labels with , um , attributes of SGML tags . So , you know , you have , say , a tag for I don't know what type of utterance , whether it 's a question or a statement or whatever . And then you have an , uh you know , an a tag attribute and the value of that encodes the choice . Oh , you mean display as in showing the waveform ? OK . Mm - hmm . Mm - hmm . Yeah , but we didn't have the exact comparison . But you know , there were i i the experiments were based on different segmentations and different transcripts . So we weren't quite sure which whether the difference came from different transcripts , for instance . And so Thilo 's But the recognizer 's putting up some resistance because it doesn't like the un - segmented data . Mmm . Yeah . Yeah . You know , I 'll bet You know , Bush went on this European trip recently and they told him there that they get more vacations . So he came back here and thought \" oh , I I can afford some more vacation too \" . Yeah . It 's hard to keep concentration , you know , and the focus on the Um . So while he 's vacationing , um , we 've been , uh Well basically this is like a joint effort . Uh , d we were just Um , @ @ you know , f apart from getting preparing the the da the data for the , um for these experiments for the , um , uh for this prosody workshop , um , we just , um we just had a phone call with Mari and her students , in fact , and they want to , um , e m They 're bringing up their own meeting recognizer , which is based on Bill Byrne 's , uh , recognizer from Johns Hopkins . u Based on their Hub - five recognizer . And , uh , so they 've been getting from us the , um you know , some support in terms of getting the latest transcripts and the also the actually the , uh , transcripts annotated with events , uh , like sentence boundaries and stuff like that . Um , because one of Mari 's students was to wants to do some language modeling for , uh , predicting overlaps and , uh , stuff like that . Um . Hmm . Mm - hmm . Yeah . Um , on the recognition side , actually , um , I think the main person doing that is , uh , Harriet from Harriet Nock from , uh formerly of Cambridge . Um , and apparently they get reasonable results except in some portions they get very high insertion rates even higher than we get with with the , um like even , you know , on lapel mikes with , uh , background speech . And so they were trying to track that down , and It could be that our recognizer 's actually doing relatively well because it has a reject model for , you know , mismatched speech , essentially , or for unspecified speech . And , um , so so , uh , they 'll I sent them our recognition output so they can sort of do a line - by - line comparison and see if if they , um you know , their insertions correspond to our rejects and stuff like that . So , um , we 'll see what that , uh , leads to . Um . Yeah . Other than that , uh , we 're Well , that 's pretty m pretty much it as far as meetings are concerned . Mm - hmm . Mm - hmm . Mm - hmm . Hmm . Right . But is it still true that basically the s speaker adaptation , um , sort of negates much of the advantage ? With it . OK . Mm - hmm . Right . Right . Mm - hmm . Yeah . OK . There 's some work , um , that Do you remember this paper or poster by , um , some CMU folks at , uh , HLT ? They were talking about and and they s they referred to an upcoming ICASSP paper , I think , at the time . Some - someone in Karlsruhe , I think , um , worked on , uh , es you know , estimating noise from the silent regions and then , uh , doing some explicit I don't know if it 's something akin to parallel model combination or something like that to to , uh , Right . Anyway , uh , so I I I couldn't judge whether this was original or not , but but it seemed like they got pretty good results on their meeting data . So we might want to look into that . Right . Right . Mm - hmm . Right . Mm - hmm . Mm - hmm . OK . Right . Hey ! We could use that in the English We have to do the English synthesis for SmartKom. What if we make the system really annoyed ? But but you can't do it I mean you can't just normalize it based on the utterance because then you 're gonna have zero everywhere . Right ? So you 'd have to normalize it based on the Yeah , OK . But that 's not really feasible because you 're having a sys you have a system , a dialogue system , where you only have access to the what the speaker said before . So it 'd have to be sort of a causal , uh , version of @ @ . Or you c u Mmm . Well , we 're not gonna build a parametric model of the o o of the of the feature . Right ? We 're just gonna we we 're gonna use like thresholding or something . Right , right . OK . Right . Right . OK . Uh , yeah . Mm - hmm . But they didn't tell her . It you know , to keep to keep us , uh OK . Hmm . Six five . L three four six . six five , six nine , O nine , eight O , four nine five four five three , two , eight seven five three nine eight three , eight six nine one , two seven four nine six nine nine nine , five , three three one four six five eight , O , nine four O two six nine , three two seven , four O five six four one three , two , five six eight three eight , three nine , seven O , seven six , seven seven . So , did you Jeremy , did you know that whoever finishes last has to buy cappuccino for everybody ?"
}