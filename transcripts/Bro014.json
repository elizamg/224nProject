{
    "meeting_id": "Bro014",
    "transcript": "Uh , channel one . Yes . OK . OK , did you solve speech recognition last week ? Alright ! Let 's do image processing . Alright ! OK . It 's April fifth . Actually , Hynek should be getting back in town shortly if he isn't already . Uh . Well , we 'll drag him here . I know where he is . U u u u uh , I meant , you know , this end of the world , yeah , is really what I meant , uh , cuz he 's been in Europe . So . Mmm . Great ! I 'm sorry , I didn't quite get that . There 's there 's four and there 's seven and I I 'm sorry . But in HTK , what 's the difference between , uh , a an inner loop and an outer loop in these iterations ? Yeah . Oh , right ! This was the mix up stuff . That 's right . I remember now . Yeah . Mm - hmm . Mm - hmm . Mm - hmm . As opposed to ? Mm - hmm . And then when you have your final thing , do a full one , so it 's Mm - hmm . That 's great . Yeah . In fact , you could do something like keep exactly the same procedure and then add a fifth thing onto it that had more . Yeah . Mm - hmm . Might be between , uh , shared , uh shared variances or something , or OK . Alright . So what else ? Oh , this is a conference call for , uh , uh , Aurora participant sort of thing . I see . Do you know who was who was since we weren't in on it , uh , do you know who was in from OGI ? Was was was Hynek involved or was it Sunil or ? Oh , you don't know . OK . Alright . Mm - hmm . Mm - hmm . Mm - hmm . Well , I mean , the fact that it 's inconsistent is an obvious mistake . But the but , um , the other thing I don't know I haven't thought it through , but one one would think that each It it 's like if you say what 's the what 's the best way to do an average , an arithmetic average or a geometric average ? It depends what you wanna show . Each each one is gonna have a different characteristic . So Well , they are doing that . No , that is relative . But the question is , do you average the relative improvements or do you average the error rates and take the relative improvement maybe of that ? And the thing is it 's not just a pure average because there are these weightings . It 's a weighted average . Um . Well , that 's what he 's seeing as one of the things they could do . It 's just when you when you get all done , I think that they pro I m I I wasn't there but I think they started off this process with the notion that you should be significantly better than the previous standard . And , um , so they said \" how much is significantly better ? what do you ? \" And and so they said \" well , you know , you should have half the errors , \" or something , \" that you had before \" . So it 's , uh , But it does seem like i i it does seem like it 's more logical to combine them first and then do the Yeah . Yeah . Oh , yeah ? Well , you know , the the thing is that if you look at the numbers on the on the more difficult cases , um , if you really believe that was gonna be the predominant use , none of this would be good enough . Nothing anybody 's whereas you sort of with some reasonable error recovery could imagine in the better cases that these these systems working . So , um , I think the hope would be that it would uh , it would work well for the good cases and , uh , it would have reasonable reas soft degradation as you got to worse and worse conditions . Um . But but No . Well , no well , no . I mean , it isn't the operating theater . I mean , they don they they don't they don't really know , I think . I mean , I th Well , I mean , I I think one thing to do is to just not rely on a single number to maybe have two or three numbers , you know , and and and say here 's how much you , uh you improve the , uh the the relatively clean case and here 's or or well - matched case , and here 's how here 's how much you , uh So . Yeah . Uh , actually it 's true . Uh , I had forgotten this , uh , but , uh , well - matched is not actually clean . What it is is just that , u uh , the training and testing are similar . So , I guess what you would do in practice is you 'd try to get as many , uh , examples of similar sort of stuff as you could , and then , uh So the argument for that being the the the more important thing , is that you 're gonna try and do that , but you wanna see how badly it deviates from that when when when the , uh it 's a little different . Um , But No . That 's a that 's a that 's an arg that 's an ar Well , that 's an argument for it , but let me give you the opposite argument . The opposite argument is you 're never really gonna have a good sample of all these different things . I mean , are you gonna have w uh , uh , examples with the windows open , half open , full open ? Going seventy , sixty , fifty , forty miles an hour ? On what kind of roads ? With what passing you ? With uh , I mean , I I I think that you could make the opposite argument that the well - matched case is a fantasy . You know , so , I think the thing is is that if you look at the well - matched case versus the po you know , the the medium and the and the fo and then the mismatched case , um , we 're seeing really , really big differences in performance . Right ? And and y you wouldn't like that to be the case . You wouldn't like that as soon as you step outside You know , a lot of the the cases it 's is I mean , in these cases , if you go from the the , uh I mean , I don't remember the numbers right off , but if you if you go from the well - matched case to the medium , it 's not an enormous difference in the in the the training - testing situation , and and and it 's a really big performance drop . You know , so , um Yeah , I mean the reference one , for instance this is back old on , uh on Italian uh , was like six percent error for the well - matched and eighteen for the medium - matched and sixty for the for highly - mismatched . Uh , and , you know , with these other systems we we helped it out quite a bit , but still there 's there 's something like a factor of two or something between well - matched and medium - matched . And so I think that if what you 're if the goal of this is to come up with robust features , it does mean So you could argue , in fact , that the well - matched is something you shouldn't be looking at at all , that that the goal is to come up with features that will still give you reasonable performance , you know , with again gentle degregra degradation , um , even though the the testing condition is not the same as the training . So , you know , I I could argue strongly that something like the medium mismatch , which is you know not compl pathological but I mean , what was the the medium - mismatch condition again ? Right . So it 's still the same same microphone in both cases , but , uh , it 's there 's a mismatch between the car conditions . And that 's uh , you could argue that 's a pretty realistic situation and , uh , I 'd almost argue for weighting that highest . But the way they have it now , it 's I guess it 's it 's They they compute the relative improvement first and then average that with a weighting ? And so then the that that makes the highly - matched the really big thing . Um , so , u i since they have these three categories , it seems like the reasonable thing to do is to go across the languages and to come up with an improvement for each of those . Just say \" OK , in the in the highly - matched case this is what happens , in the m the , uh this other m medium if this happens , in the highly - mismatched that happens \" . And , uh , you should see , uh , a gentle degradation through that . Um . But I don't know . I think that that I I I gather that in these meetings it 's it 's really tricky to make anything ac make any policy change because everybody has has , uh , their own opinion and I don't know . Yeah . Mm - hmm . Mm - hmm . Mm - hmm . So nobody would be there , probably . Right ? Good . Work to do . So whose VAD is Is is this a ? Oh , I I think th that would be good . I mean , it 's not that the design of the VAD isn't important , but it 's just that it it it does seem to be i uh , a lot of work to do a good job on on that and as well as being a lot of work to do a good job on the feature design , so if we can cut down on that maybe we can make some progress . Yeah . Um , sure . But i bu So y so you m s Yeah , but Well , let 's say for ins see , MFCC for instance doesn't have anything in it , uh , related to the pitch . So just just for example . So suppose you 've that what you really wanna do is put a good pitch detector on there and if it gets an unambiguous if it gets an unambiguous result then you 're definitely in a in a in a voice in a , uh , s region with speech . Uh . Well , for the baseline . So so if you use other features then y But it 's just a question of what is your baseline . Right ? What is it that you 're supposed to do better than ? And so having the baseline be the MFCC 's means that people could choose to pour their ener their effort into trying to do a really good VAD or tryi They 're sort of separate . Unfortunately there 's coupling between them , which is part of what I think Stephane is getting to , is that you can choose your features in such a way as to improve the VAD . And you also can choose your features in such a way as to prove improve recognition . They may not be the same thing . You should do both and and I I think that this still makes I still think this makes sense as a baseline . It 's just saying , as a baseline , we know you know , we had the MFCC 's before , lots of people have done voice activity detectors , you might as well pick some voice activity detector and make that the baseline , just like you picked some version of HTK and made that the baseline . And then let 's try and make everything better . Um , and if one of the ways you make it better is by having your features be better features for the VAD then that 's so be it . But , uh , uh , uh , at least you have a starting point that 's um , cuz i i some of the some of the people didn't have a VAD at all , I guess . Right ? And and then they they looked pretty bad and and in fact what they were doing wasn't so bad at all . But , um . Yeah . I mean , it seems like , uh , it should include sort of the current state of the art that you want are trying to improve , and MFCC 's , you know , or PLP or something it seems like reasonable baseline for the features , and anybody doing this task , uh , is gonna have some sort of voice activity detection at some level , in some way . They might use the whole recognizer to do it but rather than a separate thing , but but they 'll have it on some level . So , um . Well , I think people just had it wasn't that they purposely brain - damaged it . I think people hadn't really thought through about the , uh the VAD issue . And and then when the the the proposals actually came in and half of them had V A Ds and half of them didn't , and the half that did did well and the half that didn't did poorly . So it 's Uh . Right . When you say \" we have that \" , does Sunil have it now , too , or ? OK . OK . But how much worse since the weighting might change how how much worse is it on the other conditions , when you say it 's a little worse ? OK . Um . But it has the , uh the latencies are much shorter . That 's Uh - huh . But the latencies but you 've got the latency shorter now . Yeah . So it 's better than the system that we had before . OK . OK . So that 's that 's all fine . But what you 're saying is that when you do these So let me try to understand . When when you do these same improvements to proposal - one , that , uh , on the i things are somewhat better , uh , in proposal - two for the well - matched case and somewhat worse for the other two cases . So does , uh when you say , uh So The th now that these other things are in there , is it the case maybe that the additions of proposal - two over proposal - one are less im important ? I get it . Mm - hmm . Right . Mm - hmm . OK . There was a start of some effort on something related to voicing or something . Is that ? OK . Yeah , w what yo what you 're calling the excitation , as I recall , is you 're subtracting the the , um the mel mel mel filter , uh , spectrum from the FFT spectrum . Right . So it 's it 's not really an excitation , but it 's something that hopefully tells you something about the excitation . Yeah , yeah . Mm - hmm . Well , yeah , except the variance was big . Right ? Yeah . But another way of looking at it might be that I mean , what w we we are coming up with feature sets after all . So another way of looking at it is that um , the mel cepstru mel spectrum , mel cepstrum , any of these variants , um , give you the smooth spectrum . It 's the spectral envelope . By going back to the FFT , you 're getting something that is more like the raw data . So the question is , what characterization and you 're playing around with this another way of looking at it is what characterization of the difference between the raw data and this smooth version is something that you 're missing that could help ? So , I mean , looking at different statistical measures of that difference , coming up with some things and just trying them out and seeing if you add them onto the feature vector does that make things better or worse in noise , where you 're really just i i the way I 'm looking at it is not so much you 're trying to f find the best the world 's best voiced - unvoiced , uh , uh , classifier , but it 's more that , you know , uh , uh , try some different statistical characterizations of that difference back to the raw data and and m maybe there 's something there that the system can use . Yeah . Well , that 's the rea w w what I 'm arguing is that 's - Yeah . I mean , uh , what I 'm arguing is that that that 's givi you gives you your intuition . But in in reality , it 's you know , there 's all of this this overlap and so forth , and But what I 'm saying is that may be OK , because what you 're really getting is not actually voiced versus unvoiced , both for the fac the reason of the overlap and and then , uh , th you know , structural reasons , uh , uh , like the one that Chuck said , that that in fact , well , the data itself is that you 're working with is not perfect . So , what I 'm saying is maybe that 's not a killer because you 're just getting some characterization , one that 's driven by your intuition about voiced - unvoiced certainly , but it 's just some characterization of something back in the in the in the almost raw data , rather than the smooth version . And your intuition is driving you towards particular kinds of , uh , statistical characterizations of , um , what 's missing from the spectral envelope . Um , obviously you have something about the excitation , um , and what is it about the excitation , and , you know and you 're not getting the excitation anyway , you know . So so I I would almost take a uh , especially if if these trainings and so forth are faster , I would almost just take a uh , a scattershot at a few different ways of look of characterizing that difference and , uh , you could have one of them but and and see , you know , which of them helps . But each one of the mixture components I mean , you have , uh , uh , variance only , so it 's kind of like you 're just multiplying together these , um , probabilities from the individual features within each mixture . So it 's so , uh , it seems l you know Yeah . Um . Yeah . I mean , I know that , um , people doing some robustness things a ways back were were just doing just being gross and just throwing in the FFT and actually it wasn't wasn't wasn't so bad . Uh , so it would s and and you know that i it 's gotta hurt you a little bit to not have a a spectral , uh a s a smooth spectral envelope , so there must be something else that you get in return for that that , uh uh So . So you essentially take the values that th that you get from the triangular filter and extend them to sor sort of like a rectangle , that 's at that m value . Oh . OK . Mm - hmm . Mm - hmm . Right . Yeah . No , it 's makes sense to look at low frequencies . Right . So i so i i this is I mean , i you could argue about whether it should be linear interpolation or or or or zeroeth order , but but at any rate something like this is what you 're feeding your recognizer , typically . No . Uh , so the mel cepstrum is the is the is the cepstrum of this this , uh , spectrum or log spectrum , whatever it You - you 're subtracting in in in power domain or log domain ? OK . So it 's sort of like division , when you do the yeah , the spectra . Um . Yeah . But , anyway , um and that 's Yeah . I guess that makes sense . Yeah . Yeah . Yeah . Yeah . So , you know , all Yeah . Yeah . Pitch . Yeah . That 's like fundamental frequency . So , I mean , i t t I mean , to first order what you 'd what you 're doing I mean , ignore all the details and all the ways which is that these are complete lies . Uh , the the you know , what you 're doing in feature extraction for speech recognition is you have , uh , in your head a a a a simplified production model for speech , in which you have a periodic or aperiodic source that 's driving some filters . Uh , first order for speech recognition , you say \" I don't care about the source \" . Right ? And so you just want to find out what the filters are . The filters roughly act like a , um a , uh a an overall resonant you know , f some resonances and so forth that th that 's processing excitation . So if you look at the spectral envelope , just the very smooth properties of it , you get something closer to that . And the notion is if you have the full spectrum , with all the little nitty - gritty details , that that has the effect of both , and it would be a multiplication in in frequency domain so that would be like an addition in log power spectrum domain . And so this is saying , well , if you really do have that sort of vocal tract envelope , and you subtract that off , what you get is the excitation . And I call that lies because you don't really have that , you just have some kind of signal - processing trickery to get something that 's kind of smooth . It 's not really what 's happening in the vocal tract so you 're not really getting the vocal excitation . That 's why I was going to the why I was referring to it in a more a more , uh , uh , conservative way , when I was saying \" well , it 's yeah , it 's the excitation \" . But it 's not really the excitation . It 's whatever it is that 's different between So so , stand standing back from that , you sort of say there 's this very detailed representation . You go to a smooth representation . You go to a smooth representation cuz this typically generalizes better . Um , but whenever you smooth you lose something , so the question is have you lost something you can you use ? Um , probably you wouldn't want to go to the extreme of just ta saying \" OK , our feature set will be the FFT \" , cuz we really think we do gain something in robustness from going to something smoother , but maybe there 's something that we missed . So what is it ? And then you go back to the intuition that , well , you don't really get the excitation , but you get something related to it . And it and as you can see from those pictures , you do get something that shows some periodicity , uh , in frequency , you know , and and and also in time . So so , Yeah . But presumably you 'll see something that won't have this kind of , uh , uh , uh , regularity in frequency , uh , in the Yeah . Yeah . Yeah . Mm - hmm . Mm - hmm . Mmm . Yeah , maybe . Well , I mean it looks better , but , I mean , the thing is if if , uh if you 're actually asking you know , if you actually j uh , need to do place along an FFT , it may be it may be pushing things . And and , uh Hmm . The spectral subtraction is being done at what level ? Is it being done at the level of FFT bins or at the level of , uh , mel spectrum or something ? I mean , how are they doing it ? So in that case , it might not make much difference at all . Maybe . I mean , certainly it 'd be better . Yeah . Yeah . OK . What else ? @ @ OK . Uh , has has anything happened yet on this business of having some sort of standard , uh , source , or ? OK . Early June , late June , middle June ? Hmm . OK . Um , and he 's been doing all the talking but but these he 's he 's , uh This is this by the way a bad thing . We 're trying to get , um , m more female voices in this record as well . So . Make sur make sure Carmen talks as well . Uh , but has he pretty much been talking about what you 're doing also , and ? Yes . Yeah , well . You know , uh , we 'll get we 'll get to , uh , Spanish voices sometime , and we do we want to recognize , uh , you too . Oh , no . We like we we 're we 're w we are we 're in the , uh , Bourlard - Hermansky - Morgan , uh , frame of mind . Yeah , we like high error rates . It 's That way there 's lots of work to do . So it 's Uh , anything to talk about ? Mm - hmm . This is in order to use the SRI system or something . Right ? Yeah ? Oh , OK . Yeah . I mean , it 's um , certainly in a short short - term this just sounds easier . Yeah . I mean , longer - term if it 's if it turns out to be useful , one one might want to do something else , but Uh , uh , I mean , in in other words , you you may be putting other kinds of errors in from the re - synthesis process . Yeah . Uh , it depends what you what you do . I mean , it 's it 's it 's , uh , um Don't know . But anyway it sounds like a reasonable way to go for a for an initial thing , and we can look at at exactly what you end up doing and and then figure out if there 's some something that could be be hurt by the end part of the process . OK . So that 's That was it , huh ? OK . OK . Um , anything to add ? Yeah . Yeah . Sure . I mean , this sort of goes back to earlier stuff by Drullman . And and , uh , the the MSG features were sort of built up with this notion But , I guess , I thought you had brought this up in the context of , um , targets somehow . But i m i it 's not I mean , they 're sort of not in the same kind of category as , say , a phonetic target or a syllabic target or a or a feature or something . Oh , I see . Well , that 's sort of what MSG does . Right ? So it 's But but , uh Yeah . Anyway , we 'll talk more about it later . Yeah . Yeah . Yeah . So maybe , le let 's do digits . Let you you start . Transcript L fifty - five , or transcript L five five . Six eight seven , seven one five , zero seven five . Eight nine six zero , three , eight six five . Five six six , two zero , zero two nine six . Eight four two eight , nine , one six four . One six eight , six two , four zero one three . Three one , two six , six one , nine nine , six zero . Eight three seven zero , eight , zero eight zero . Six two three six , four zero zero six , nine seven four three ."
}