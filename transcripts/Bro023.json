{
    "meeting_id": "Bro023",
    "transcript": "Damn . Mm - hmm . Mm - hmm . Mmm . The baseline is something similar to a w I mean , the t the the baseline that you are talking about is the MFCC baseline , right ? Or ? Mm - hmm . Yeah , so it looks to be , um Yep , it 's three point four , uh , eight point , uh , seven , and , uh , thirteen point seven . Mm - hmm . No , I don't think so . Is it on Italian ? Oh , yeah , fifty - seven Right . Uh - huh . Mm - hmm . So it 's the close - talking microphone . Yeah , so actually I received a a new document , describing this . And what they did finally is to , mmm , uh , not to align the utterances but to perform recognition , um , only on the close - talking microphone , and to take the result of the recognition to get the boundaries uh , of speech . And Uh , I think they will send , um , files but we we don't Well , apparently Yeah . Yeah . Oh , i Yeah , so what happened here is that , um , the overall improvement that they have with this method So Well , to be more precise , what they have is , they have these alignments and then they drop the beginning silence and and the end silence but they keep , uh , two hundred milliseconds before speech and two hundred after speech . And they keep the speech pauses also . Um , and the overall improvement over the MFCC baseline So , when they just , uh , add this frame dropping in addition it 's r uh , forty percent , right ? Fourteen percent , I mean . Um , which is , um , t which is the overall improvement . But in some cases it doesn't improve at all . Like , uh , y do you remember which case ? Yeah , some @ @ . Right . Mmm . Yeah . And Yeah , the other thing also is that fourteen percent is less than what you obtain using a real VAD . So with without cheating like this . So Uh So I think this shows that there is still work Uh , well , working on the VAD is still still important I think . Uh Mm - hmm . Mm - hmm . Uh , yeah . So , I 've been , uh , working still on the spectral subtraction . Um , So to r to remind you a little bit of of what I did before , is just to apply some spectral subtraction with an overestimation factor also to get , um , an estimate of the noise , uh , spectrum , and subtract this estimation of the noise spectrum from the , uh , signal spectrum , but subtracting more when the SNR is is , uh , low , which is a technique that it 's often used . So you overestimate the noise spectrum . You multiply the noise spectrum by a factor , uh , which depends on the SNR . So , above twenty DB , it 's one , so you just subtract the noise . And then it 's b Generally Well , I use , actually , a linear , uh , function of the SNR , which is bounded to , like , two or three , when the SNR is below zero DB . Um , doing just this , uh , either on the FFT bins or on the mel bands , um , t doesn't yield any improvement o Yeah . So there is also a threshold , of course , because after subtraction you can have negative energies , and So what I I just do is to put , uh to to add to put the threshold first and then to add a small amount of noise , which right now is speech - shaped . Um Yeah , so it 's a it has the overall overall energy , uh pow it has the overall power spectrum of speech . So with a bump around one kilohertz . i Uh - huh . Yeah . There can be frequency bins with negative values . For each frequencies I a I 'm adding some , uh , noise , but the a the amount of the amount of noise I add is not the same for all the frequency bins . Uh . Right now I don't think if it makes sense to add something that 's speech - shaped , because then you have silence portion that have some spectra similar to the sp the overall speech spectra . But Yeah . So this is something I can still work on , but Hmm . That means that Mm - hmm . Yeah . So so yeah , you have an an estimation of the noise spectrum , but sometimes , of course , it 's as the noise is not perfectly stationary , sometimes this estimation can be , uh , too small , so you don't subtract enough . But sometimes it can be too large also . If if the noise , uh , energy in this particular frequency band drops for some reason . Mmm . Mm - hmm , yeah . Mm - hmm . Mm - hmm . Hmm . Mm - hmm . Mm - hmm . And , yeah , some people also if it 's a negative value they , uh , re - compute it using inter interpolation from the edges and bins . Well , there are different things that you can do . Mm - hmm . Mm - hmm . Yep . Well , actually I tried , something else based on this , um , is to to put some smoothing , um , because it seems to to help or it seems to help the Wiener filtering and , mmm So what I did is , uh , some kind of nonlinear smoothing . Actually I have a recursion that computes Yeah , let me go back a little bit . Actually , when you do spectral subtraction you can , uh , find this this equivalent in the s in the spectral domain . You can uh compute , y you can say that d your spectral subtraction is a filter , um , and the gain of this filter is the , um , signal energy minus what you subtract , divided by the signal energy . And this is a gain that varies over time , and , you know , of course , uh , depending on the s on the noise spectrum and on the speech spectrum . And what happen actually is that during low SNR values , the gain is close to zero but it varies a lot . Mmm , and this this is the cause of musical noise and all these the the fact you we go below zero one frame and then you can have an energy that 's above zero . And Mmm . So the smoothing is I did a smoothing actually on this gain , uh , trajectory . But it 's the smoothing is nonlinear in the sense that I tried to not smooth if the gain is high , because in this case we know that , uh , the estimate of the gain is correct because we we are not close to to to zero , um , and to do more smoothing if the gain is low . Mmm . Um . Yeah . So , well , basically that 's this idea , and it seems to give pretty good results , uh , although I 've just just tested on Italian and Finnish . And on Italian it seems my result seems to be a little bit better than the Wiener filtering , right ? Uh , I don't know if you have these improvement the detailed improvements for Italian , Finnish , and Spanish there or you have just have your own . Mm - hmm . Uh uh , no , we 've Mm - hmm . Yeah . On Italian . But on Finnish it 's a little bit worse , apparently . Um Yeah . Uh , so , it 's , uh , three point , uh , eight . Am I right ? And then , uh , d uh , nine point , uh , one . And finally , uh , sixteen point five . Plus plus nonlinear smoothing . Well , it 's the system it 's exactly the sys the same system as Sunil tried , but Yeah . But instead of double stage Wiener filtering , it 's it 's this smoothed spectral subtraction . Um , yeah . For what ? It it 's Wiener filtering , am I right ? Well , it 's some kind of Wiener filtering Yeah . Mm - hmm . Yeah . But they also have two two different smoothing @ @ . One in the time domain and one in the frequency domain by just taking the first , um , coefficients of the impulse response . So , basically it 's similar . I mean , what you did , it 's similar because you have also two two kind of smoothing . One in the time domain , and one in the frequency domain , yeah . Um Yeah . Yeah . Mm - hmm . Uh , actually the the smoothing that I did do here reduced the musical noise . Well , it Mmm . Well , I cannot you cannot hear beca well , actually what I d did not say is that this is not in the FFT bins . This is in the mel frequency bands . Um So , it could be seen as a f a a smoothing in the frequency domain because I used , in ad mel bands in addition and then the other phase of smoothing in the time domain . Mmm . But , when you look at the spectrogram , if you don't have an any smoothing , you clearly see , like in silence portions , and at the beginning and end of speech , you see spots of high energy randomly distributed over the the spectrogram . Um Which is musical noise , yeah , if if it If you listen to it uh , if you do this in the FFT bins , then you have spots of energy randomly distributing . And if you f if you re - synthesize these spot sounds as , like , sounds , uh And Mm - hmm . Yeah . Yeah . Um Yeah , although if if we , um , look at the result from the proposals , one of the reason , uh , the n system with the neural net was , um , more than well , around five percent better , is that it was much better on highly mismatched condition . I 'm thinking , for instance , on the TI - digits trained on clean speech and tested on noisy speech . Uh , for this case , the system with the neural net was much better . But not much on the in the other cases . And if we have no , uh , spectral subtraction or Wiener filtering , um , i the system is Uh , we thought the neural neural network is much better than before , even in these cases of high mismatch . So , maybe the neural net will help less but , um Mm - hmm . Mm - hmm . Mm - hmm . Mm - hmm . Mm - hmm . Mm - hmm . Mm - hmm . Mm - hmm . Yeah , yeah . Um , Yeah , so this is th the , um Well , actually , this was kind of the first try with this spectral subtraction plus smoothing , and I was kind of excited by the result . Um , then I started to optimize the different parameters . And , uh , the first thing I tried to optimize is the , um , time constant of the smoothing . And it seems that the one that I chose for the first experiment was the optimal one , so uh , Um , so this is the first thing . Um Yeah , another thing that I it 's important to mention is , um , that this has a this has some additional latency . Um . Because when I do the smoothing , uh , it 's a recursion that estimated the means , so of the g of the gain curve . And this is a filter that has some latency . And I noticed that it 's better if we take into account this latency . So , instead o of using the current estimated mean to , uh , subtract the current frame , it 's better to use an estimate that 's some somewhere in the future . Um Yeah . It 's the recursion , so it 's it 's the center recursion , right ? Um and the latency of this recursion is around fifty milliseconds . @ @ Five zero , yeah . Um , mmm . Yeah , the mean estimation has some delay , right ? I mean , the the filter that that estimates the mean has a time constant . Yeah . It 's , uh , not as good . It 's not bad . Um , it helps a lot over the ba the baseline but , mmm it It 's around three percent , um , relative . Yeah . Yeah . Um , mmm So , uh Yeah , but Yeah . So , yeah , it depends . Uh , y actually , it 's it 's l it 's three percent . Right . Mmm . Yeah , b but I don't think we have to worry too much on that right now while you kno . Mm - hmm . So Mm - hmm . Mm - hmm . Yeah . Oh yes . s Mm - hmm . Yeah . Um . So , yeah , there are other things in the , um , algorithm that I didn't , uh , @ @ a lot yet , which Mm - hmm . No , it 's it 's added . Mm - hmm . Mmm . Yeah . Mm - hmm . Yeah . Mm - hmm . Yeah . Mm - hmm . Yeah . So , um , there is uh , these parameters that I still have to to look at . Like , I played a little bit with this overestimation factor , uh , but I still have to to look more at this , um , at the level of noise I add after . Uh , I know that adding noise helped , um , the system just using spectral subtraction without smoothing , but I don't know right now if it 's still important or not , and if the level I choose before is still the right one . Same thing for the shape of the the noise . Maybe it would be better to add just white noise instead of speech shaped noise . Mm - hmm . Um , yep . Uh , and another thing is to Yeah , for this I just use as noise estimate the mean , uh , spectrum of the first twenty frames of each utterance . I don't remember for this experiment what did you use for these two stage The ten frames ? Mm - hmm . Um . But , so what 's this result you told me about , the fact that if you use more than ten frames you can improve by t Oh , OK . But this is ten frames plus plus channel Uh , no , these results with two stage Wiener filtering is ten frames but possibly more . I mean , if channel one VAD gives you Yeah . OK . Yeah , but in this experiment I did I didn't use any VAD . I just used the twenty first frame to estimate the noise . And So I expected it to be a little bit better , if , uh , I use more more frames . Um . OK , that 's it for spectral subtraction . The second thing I was working on is to , um , try to look at noise estimation , mmm , and using some technique that doesn't need voice activity detection . Um , and for this I u simply used some code that , uh , I had from from Belgium , which is technique that , um , takes a bunch of frame , um , and for each frequency bands of this frame , takes a look at the minima of the energy . And then average these minima and take this as an an energy estimate of the noise for this particular frequency band . And there is something more to this actually . What is done is that , uh , these minima are computed , um , based on , um , high resolution spectra . So , I compute an FFT based on the long , uh , signal frame which is sixty - four millisecond What what I what I d uh , I do actually , is to take a bunch of to take a tile on the spectrogram and this tile is five hundred milliseconds long and two hundred hertz wide . And this tile Uh , in this tile appears , like , the harmonics if you have a voiced sound , because it 's it 's the FTT bins . And when you take the m the minima of of these this tile , when you don't have speech , these minima will give you some noise level estimate , If you have voiced speech , these minima will still give you some noise estimate because the minima are between the harmonics . And If you have other other kind of speech sounds then it 's not the case , but if the time frame is long enough , uh , like s five hundred milliseconds seems to be long enough , you still have portions which , uh , are very close whi which minima are very close to the noise energy . Mmm ? Sixty - four milliseconds is to compute the FFT , uh , bins . The the FFT . Um , actually it 's better to use sixty - four milliseconds because , um , if you use thirty milliseconds , then , uh , because of the this short windowing and at low pitch , uh , sounds , the harmonics are not , wha uh , correctly separated . So if you take these minima , it b they will overestimate the noise a lot . So I take to I take a bunch of these sixty - four millisecond frame to cover five hundred milliseconds , and then I look for the minima , on the on on the bunch of uh fifty frames , right ? Mmm . So the interest of this is that , as y with this technique you can estimate u some reasonable noise spectra with only five hundred milliseconds of of signal , so if the the n the noise varies a lot , uh , you can track better track the noise , which is not the case if you rely on the voice activity detector . So even if there are no no speech pauses , you can track the noise level . The only requirement is that you must have , in these five hundred milliseconds segment , you must have voiced sound at least . Cuz this these will help you to to track the the noise level . Um . So what I did is just to simply replace the VAD - based , uh , noise estimate by this estimate , first on SpeechDat - Car Well , only on SpeechDat - Car actually . And it 's , uh , slightly worse , like one percent relative compared to the VAD - based estimates . Um , I think the reason why it 's not better , is that the SpeechDat - Car noises are all stationary . Um . So , u y y there really is no need to have something that 's adaptive and Uh , well , they are mainly stationary . Um . But , I expect s maybe some improvement on TI - digits because , nnn , in this case the noises are all sometimes very variable . Uh , so I have to test it . Mmm . Mm - hmm . It 's It 's the France - Telecom - based spectra , s uh , Wiener filtering and VAD . So it 's their system but just I replace their noise estimate by this one . In i I 'm not No , no . Yeah , it 's our system but with just the Wiener filtering from their system . Right ? Mmm . Yeah . Actually , th the best system that we still have is , uh , our system but with their noise compensation scheme , right ? So I 'm trying to improve on this , and by by replacing their noise estimate by , uh , something that might be better . Yeah . Yeah . But I di Not yet , because I did this in parallel , and I was working on one and the other . Um , Yeah , for for sure I will . I can try also , mmm , the spectral subtraction . Mm - hmm . Mm - hmm . Um . Yeah . I , um , also implemented a sp um spectral whitening idea which is in the , um , Ericsson proposal . Uh , the idea is just to um , flatten the log , uh , spectrum , um , and to flatten it more if the the probability of silence is higher . So in this way , you can also reduce somewhat reduce the musical noise and you reduce the variability if you have different noise shapes , because the the spectrum becomes more flat in the silence portions . Um . Yeah . With this , no improvement , uh , but there are a lot of parameters that we can play with and , um Actually , this this could be seen as a soft version of the frame dropping because , um , you could just put the threshold and say that \" below the threshold , I will flatten comp completely flatten the the spectrum \" . And above this threshold , uh , keep the same spectrum . So it would be like frame dropping , because during the silence portions which are below the threshold of voice activity probability , uh , w you would have some kind of dummy frame which is a perfectly flat spectrum . And this , uh , whitening is something that 's more soft because , um , you whiten you just , uh , have a function the whitening is a function of the speech probability , so it 's not a hard decision . Um , so I think maybe it can be used together with frame dropping and when we are not sure about if it 's speech or silence , well , maybe it has something do with this . Mm - hmm . Mm - hmm . Mm - hmm . Mm - hmm . Yeah , w Yeah , right now it 's a constant that just depending on the the noise spectrum . Mm - hmm . Mm - hmm . Mm - hmm . Mm - hmm . So . Yeah . Uh Yeah , so there are with this technique there are some I just did something exactly the same as as the Ericsson proposal but , um , the probability of speech is not computed the same way . And I think , i for yeah , for a lot of things , actually a g a good speech probability is important . Like for frame dropping you improve , like you can improve from ten percent as Sunil showed , if you use the channel zero speech probabilities . For this it might help , um S so , yeah . Uh , so yeah , the next thing I started to do is to , uh , try to develop a better voice activity detector . And , um I d um yeah , for this I think we can maybe try to train the neural network for voice activity detection on all the data that we have , including all the SpeechDat - Car data . Um And so I 'm starting to obtain alignments on these databases . Um , and the way I mi I do that is that I just use the HTK system but I train it only on the close - talking microphone . And then I aligned I obtained the Viterbi alignment of the training utterances . Um It seems to be , uh i Actually what I observed is that for Italian it doesn't seem Th - there seems to be a problem . Well . Because What ? Yeah . Yeah . So , u but actually the VAD was trained on Italian also , so Um , the c the current VAD that we have was trained on , uh , t SPINE , right ? Italian , and TI - digits with noise and Uh , yeah . And it seems to work on Italian but not on the Finnish and Spanish data . So , maybe one reason is that s s Finnish and Spanish noise are different . And actually we observed we listened to some of the utterances and sometimes for Finnish there is music in the recordings and strange things , right ? Um Yeah , so the idea was to train all the databases and obtain an alignment to train on these databases , and , um , also to , um , try different kind of features , uh , as input to the VAD network . And we came up with a bunch of features that we want to try like , um , the spectral slope , the , um , the degree o degree of voicing with the features that , uh , we started to develop with Carmen , um , e with , uh , the correlation between bands and different kind of features , and Yeah . The energy . Yeah . Of course . Yeah . Mm - hmm . Transcript L dash two eight six . Three seven five , four five , one four six nine . Three , five four three , five three , one five zero , nine . Six eight five two , five eight two one , four three four four . Eight , two six five , five eight , zero zero eight , one . Five three nine six , one zero five five , three three eight three . Five zero one , one nine five , nine one zero . Five , three four three , one one , seven eight five , nine . Six zero five zero , one one eight seven , two three nine one ."
}