{
    "meeting_id": "Bro025",
    "transcript": "Yeah . So . Yeah . Almost . Yeah . Mm - hmm . So it 's well , it 's spectral subtraction or Wiener filtering , um , depending on if we put if we square the transfer function or not . And then with over - estimation of the noise , depending on the , uh the SNR , with smoothing along time , um , smoothing along frequency . It 's very simple , smoothing things . And , um , the best result is when we apply this procedure on FFT bins , uh , with a Wiener filter . And there is no noise addition after after that . So it 's good because it 's difficult when we have to add noise to to to find the right level . Yeah . So the sh it 's the sheet that gives fifty - f three point sixty - six . Um , the second sheet is abo uh , about the same . It 's the same , um , idea but it 's working on mel bands , and it 's a spectral subtraction instead of Wiener filter , and there is also a noise addition after , uh , cleaning up the mel bins . Mmm . Well , the results are similar . Mm - hmm . It 's worse on on the multi - condition in TI - digits . Yeah . Mmm . Yeah . So now we are , yeah , setting up the software . Um , it should be ready , uh , very soon . Um , and we @ @ p - p - p Oh boy . Yeah . I need to allow it to do everything and even more more than this . Well , if we want to , like , optimize different parameters of Yeah , we can do it later . But , still so , there will be a piece of software with , uh , will give this system , the fifty - three point sixty - six , by default and Mm - hmm . It 's just one percent off of the best proposal . It 's between i we are second actually if we take this system . Right ? Mm - hmm . Yeah . Mm - hmm . Mm - hmm . Mmm . Mm - hmm . Yeah . Yeah . Right . Mm - hmm . Uh , so th um , they keep two hundred milliseconds at the beginning and end of speech . And they keep all the Yeah . And all the speech pauses , which is Sometimes on the SpeechDat - Car you have pauses that are more than one or two seconds . More than one second for sure . Um . Yeah . And , yeah , it seems to us that this way of just dropping the beginning and end is not We cou we can do better , I think , because , um , with this way of dropping the frames they improve over the baseline by fourteen percent and Sunil already showed that with our current VAD we can improve by more than twenty percent . @ @ Just using either their VAD or our current VAD . So , our current VAD is is more than twenty percent , while their is fourteen . Yeah . So . Yeah . And another thing that we did also is that we have all this training data for let 's say , for SpeechDat - Car . We have channel zero which is clean , channel one which is far - field microphone . And if we just take only the , um , VAD probabilities computed on the clean signal and apply them on the far - field , uh , test utterances , then results are much better . In some cases it divides the error rate by two . So it means that there are stim still If if we can have a good VAD , well , it would be great . Uh , right now it 's , um , a neural net with nine frames . So it 's forty milliseconds plus , um , the rank ordering , which , uh , should be ten Yeah . So , right now it 's one hundred and forty milliseconds . The The , um Yeah . It 's not a median filtering . It 's just We don't take the median value . We take something Um , so we have eleven , um , frames . And for the VAD , yeah and we take th the third . Um . Mmm . Mm - hmm . Mmm . Mm - hmm . Yeah . Uh - huh . Mm - hmm . Just the frame - dropping problem . Yeah . But it 's it 's difficult . Sometime we we change two two things together and But it 's around maybe it 's less than one percent . It Yeah . Yeah . And it Yeah . And then we have to be careful with that also with the neural net because in the proposal the neural net was also , uh , working on after frame - dropping . Um . So . Well , we 'll have to be to do the same kind of correction . Mmm . Well , we can do the frame - dropping on the server side or we can just be careful at the terminal side to send a couple of more frames before and after , and So . I think it 's OK . Mm - hmm . Mm - hmm . Mm - hmm . Mm - hmm . So , we , uh actually I did the first experiment . This is with just fifteen frames . Um . We take the first fifteen frame of each utterance to it , and average their power spectra . Um . I tried just plugging the , um , uh , Guenter noise estimation on this system , and it uh , it got worse . Um , but of course I didn't play with it . But Mm - hmm . Uh , I didn't do much more for noise estimation . I just tried this , and Mm - hmm . Mm - hmm . Yeah , I guess . Mmm . No , we don't . We don't have nothing that Yeah . Mm - hmm . Yeah . Mm - hmm . Mm - hmm . Yeah . So , should we keep the same ? I think we might try to keep the same idea of having a neural network , but training it on more data and adding better features , I think , but because the current network is just PLP features . Well , it 's trained on noisy PLP PLP features computed on noisy speech . But there is no nothing particularly robust in these features . There 's no RASTA , no Oh , yeah . Hmm . Mm - hmm . Mmm . And it seems important for , like , the on - line normalization . Um . We don't want to update the mean and variance during silen long silence portions . Um . So it it has to be done before this mean and variance normalization . Um . Mm - hmm . The Half Dome was great . Transcript L dash three two eight . Nine nine zero , six zero , three nine five five . Nin - nine eight four , three one , six five three four . Two four three , one one four , four one six six . Four one , nine four , three three , seven six , five five . Five zero five , seven five four , zero seven five . Six six three zero , five , four eight seven . Seven zero one , eight one two , eight three one . Five seven , three four , eight seven , zero three , six eight ."
}