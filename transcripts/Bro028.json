{
    "meeting_id": "Bro028",
    "transcript": "Eh , we should be going . Couldn't you t couldn't you , um , test the human performance on just the original audio ? Oh , oh . OK , I see . OK . So , y uh , your performance was one percent , and then when you re - synthesize with LPC - twelve it went to five . OK . But But from this it 's pretty safe to say that the system is with either two to seven percent away from the performance of a human . Right ? So it 's somewhere in that range . Two two to six percent . In the LPC synthesis ? I think So I 've , um , downloaded , uh , a couple of things from Mississippi State . Um , one is their software their , uh , LVCSR system . Downloaded the latest version of that . Got it compiled and everything . Um , downloaded the scripts . They wrote some scripts that sort of make it easy to run the system on the Wall Street Journal , uh , data . Um , so I haven't run the scripts yet . Uh , I 'm waiting there was one problem with part of it and I wrote a note to Joe asking him about it . So I 'm waiting to hear from him . But , um , I did print something out just to give you an idea about where the system is . Uh , they on their web site they , uh , did this little table of where their system performs relative to other systems that have done this this task . And , um , the Mississippi State system using a bigram grammar , uh , is at about eight point two percent . Other comparable systems from , uh were getting from , uh , like six point nine , six point eight percent . So they 're This is on clean on clean stuff . Yeah . They they 've started a table where they 're showing their results on various different noise conditions but they they don't have a whole lot of it filled in and and I didn't notice until after I 'd printed it out that , um , they don't say here what these different testing conditions are . You actually have to click on it on the web site to see them . So I I don't know what those numbers really mean . Well , see , I was a little confused because on this table , I 'm the they 're showing word error rate . But on this one , I I don't know if these are word error rates because they 're really big . So , under condition one here it 's ten percent . Then under three it goes to sixty - four point six percent . Yeah . So m I guess maybe they 're error rates but they 're , uh they 're really high . So Correct ? Accuracy ? Oh , oh , on digits . Yeah . OK . Yeah . Yeah . Oh , is it ? OK . So , yeah , that 's probably what it is then . Yeah . So they have a lot of different conditions that they 're gonna be filling out . Yeah . Yeah . It 's it 's gonna be hard . Um , they 're I I 'm still waiting for them to release the , um , multi - CPU version of their scripts , cuz right now their script only handles processing on a single CPU , which will take a really long time to run . So . But their s Uh I beli Yes , for the training also . And , um , they 're supposed to be coming out with it any time , the multi - CPU one . So , as soon as they get that , then I 'll I 'll grab those too and so w Yeah . Yeah . I 'll go ahead and try to run it though with just the single CPU one , and I they they , um , released like a smaller data set that you can use that only takes like sixteen hours to train and stuff . So I can I can run it on that just to make sure that the the thing works and everything . It wasn't on the conference call this morning ? Hmm . Did they say anything on the conference call about , um , how the Wall Street Journal part of the test was going to be run ? Because I I thought I remembered hearing that some sites were saying that they didn't have the compute to be able to run the Wall Street Journal stuff at their place , so there was some talk about having Mississippi State run the systems for them . And I Did did that come up at all ? Oh , OK . Hmm - mm . The only , um , mail I get is from Mississippi State so about their system . I I don't get any mail about Yeah . Yeah . It does . Yeah . I 'm I 'm wondering about that because there 's this whole issue about , you know , simple tuning parameters , like word insertion penalties . And whether or not those are going to be tuned or not , and So . I mean , it makes a big difference . If you change your front - end , you know , the scale is completely can be completely different , so . It seems reasonable that that at least should be tweaked to match the front - end . But I did , but Joe said , you know , \" what you 're saying makes sense and I don't know \" . So he doesn't know what the answer is . I mean , that 's th We had this back and forth a little bit about , you know , are sites gonna are you gonna run this data for different sites ? And , well , if if Mississippi State runs it , then maybe they 'll do a little optimization on that parameter , and , uh But then he wasn't asked to run it for anybody . So i it 's it 's just not clear yet what 's gonna happen . Uh , he 's been putting this stuff out on their web site and for people to grab but I haven't heard too much about what 's happening . I wonder if it it might be possible to , uh , simulate the back - end with some other system . So we we get our f front - end features , and then , uh , as part of the process of figuring out the scaling of these features , you know , if we 're gonna take it to a root or to a power or something , we have some back - end that we attach onto our features that sort of simulates what would be happening . Um , and just adjust it until that our l version of the back - end , uh , decides that that Yeah . Oh , yeah . That 's true . And then we just use that to determine some scaling factor that we use . Mm - hmm . Mm - hmm . Yeah . Uh , w what do you mean when you say \" what kind \" ? Yeah . Gaussian mixture model . It 's the same system that they use when they participate in the Hub - five evals . It 's a , um sort of came out of , uh uh , looking a lot like HTK . I mean , they started off with um , when they were building their system they were always comparing to HTK to make sure they were getting similar results . And so , it 's a Gaussian mixture system , uh I don't know . Yeah . And then divide the mixtures in half . I don't know if they do that . I 'm not really sure . Yeah , th I have I I I don't have it up here but I have a the whole system description , that describes exactly what their system is and I I 'm not sure . But , um It 's some kind of a mixture of Gaussians and , uh , clustering and , uh They 're they 're trying to put in sort of all of the standard features that people use nowadays . Hmm . Hmm . So is this a histogram across different frequency bins ? Or ? So , one histogram per frequency bin . And that 's So th Oh . Huh . And and that that , um , histogram represents the different energy levels that have been seen at that frequency ? Uh - huh . So they , uh Is the idea that you you run a test utterance through some histogram generation thing and then you compare the histograms and that tells you what to do to the utterance to make it more like ? I see . Hmm . Yeah . Hmm . Mm - hmm . Hmm . H What does he do to choose those ? Hmm ! So it 's a it 's a little bit like a genetic algorithm or something in a way . Greedy . Hmm . That 's ri Transcript L dash three six nine . Zero two six zero , nine nine eight five , four four nine four . Three , nine eight five , seven five , six four zero , three . Four nine six , two six , seven zero zero one . Nine four two , one two zero , seven six seven . One seven seven , four six eight , two eight nine . Two five , one nine , three seven , two eight , five two . One seven three , five seven seven , two eight six four . Seven eight eight , three one three , five seven six . OK ."
}